# Python Type Annotations ç§‘å­¦è®¡ç®—æŒ‡å—

## ğŸ“Œ æ¦‚è¿°

Type Annotationsï¼ˆç±»å‹æ³¨è§£ï¼‰æ˜¯ Python 3.5+ å¼•å…¥çš„é‡è¦ç‰¹æ€§ï¼Œå…è®¸å¼€å‘è€…æ˜¾å¼æŒ‡å®šå˜é‡ã€å‡½æ•°å‚æ•°å’Œè¿”å›å€¼çš„ç±»å‹ã€‚åœ¨ç§‘å­¦è®¡ç®—ä¸­ï¼Œåˆç†çš„ç±»å‹æ³¨è§£å¯ä»¥ï¼š

- æé«˜ä»£ç å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§
- åˆ©ç”¨ IDE æ™ºèƒ½æç¤ºå’Œé™æ€æ£€æŸ¥
- å‡å°‘ç±»å‹ç›¸å…³çš„è¿è¡Œæ—¶é”™è¯¯
- æ–¹ä¾¿å›¢é˜Ÿåä½œå’Œä»£ç å®¡æŸ¥

## ğŸ¯ ä¸ºä»€ä¹ˆç§‘å­¦è®¡ç®—éœ€è¦ Type Annotations

1. **æ•°å€¼ç²¾åº¦æ§åˆ¶**ï¼šæ˜ç¡®åŒºåˆ† `float32`ã€`float64`ã€`int32`ã€`int64`
2. **æ•°ç»„ç»´åº¦**ï¼šä½¿ç”¨ `typing.NewType` åŒºåˆ†æ ‡é‡ã€å‘é‡ã€çŸ©é˜µ
3. **å¤æ‚å¯¹è±¡**ï¼šæ˜ç¡®æ•°æ®é›†ã€æ¨¡å‹å‚æ•°ã€ç»“æœç±»å‹
4. **å‡½æ•°ç­¾å**ï¼šæ¸…æ™°è¡¨è¾¾æ•°å­¦å‡½æ•°çš„è¾“å…¥è¾“å‡ºå…³ç³»

## ğŸ”§ åŸºç¡€è¯­æ³•

### 1. å˜é‡æ³¨è§£

```python
from typing import Union, Optional
import numpy as np

# åŸºæœ¬ç±»å‹
learning_rate: float = 0.001
batch_size: int = 32
use_gpu: bool = True

# å¯é€‰ç±»å‹
model_name: Optional[str] = None
validation_split: Union[float, None] = None

# NumPy æ•°ç»„ç±»å‹
weights: np.ndarray = np.random.randn(784, 10)
input_data: np.ndarray = np.zeros((100, 28, 28, 3))

# æŒ‡å®š dtype
weights_float32: np.ndarray = np.random.randn(784, 10).astype(np.float32)
labels_int64: np.ndarray = np.random.randint(0, 10, size=(1000,), dtype=np.int64)
```

### 2. å‡½æ•°æ³¨è§£

```python
from typing import Tuple, List, Dict, Any, Union, Callable

# ç®€å•å‡½æ•°
def mean_squared_error(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """è®¡ç®—å‡æ–¹è¯¯å·®"""
    return np.mean((y_true - y_pred) ** 2)

# å¤æ‚è¿”å›ç±»å‹
def train_test_split(
    data: np.ndarray,
    labels: np.ndarray,
    test_size: float = 0.2,
    random_state: int = 42
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """åˆ†å‰²æ•°æ®é›†"""
    # å®ç°ä»£ç ...
    return X_train, X_test, y_train, y_test

# å¯å˜å‚æ•°
def fit_model(
    X: np.ndarray,
    y: np.ndarray,
    **kwargs: Any
) -> Dict[str, Union[float, np.ndarray, List[float]]]:
    """è®­ç»ƒæ¨¡å‹å¹¶è¿”å›å†å²è®°å½•"""
    history = {}
    # è®­ç»ƒè¿‡ç¨‹...
    return history

# å›è°ƒå‡½æ•°
def optimization_callback(
    epoch: int,
    metrics: Dict[str, float],
    model_params: np.ndarray
) -> bool:
    """ä¼˜åŒ–å›è°ƒï¼Œè¿”å›æ˜¯å¦æå‰åœæ­¢"""
    return metrics['loss'] < 1e-6
```

## ğŸ“Š ç§‘å­¦è®¡ç®—ä¸­çš„é«˜çº§ç±»å‹å®šä¹‰

### 1. ä½¿ç”¨ NewType åˆ›å»ºè¯­ä¹‰åŒ–ç±»å‹

```python
from typing import NewType
import numpy as np

# åˆ›å»ºè¯­ä¹‰åŒ–ç±»å‹
TimeSeries = NewType('TimeSeries', np.ndarray)
FrequencySeries = NewType('FrequencySeries', np.ndarray)
Scalar = NewType('Scalar', float)
Vector3D = NewType('Vector3D', np.ndarray)
Matrix3x3 = NewType('Matrix3x3', np.ndarray)
Probability = NewType('Probability', float)

# ä½¿ç”¨ç¤ºä¾‹
def autocorrelation(signal: TimeSeries) -> TimeSeries:
    """è®¡ç®—è‡ªç›¸å…³å‡½æ•°"""
    # å®ç°è‡ªç›¸å…³è®¡ç®—
    return TimeSeries(result)

def vector_magnitude(vector: Vector3D) -> Scalar:
    """è®¡ç®—3Då‘é‡æ¨¡é•¿"""
    return Scalar(np.linalg.norm(vector))
```

### 2. ä½¿ç”¨ TypeVar åˆ›å»ºæ³›å‹

```python
from typing import TypeVar, Generic, Protocol
import numpy as np

T = TypeVar('T', np.ndarray, float, int)

class DataProcessor(Generic[T]):
    """é€šç”¨æ•°æ®å¤„ç†å™¨"""

    def __init__(self, data: T):
        self.data = T(data)

    def apply_filter(self, filter_func: Callable[[T], T]) -> T:
        """åº”ç”¨æ»¤æ³¢å™¨"""
        return T(filter_func(self.data))

# åè®®å®šä¹‰
class Model(Protocol):
    """æ¨¡å‹åè®®"""

    def fit(self, X: np.ndarray, y: np.ndarray) -> 'Model':
        ...

    def predict(self, X: np.ndarray) -> np.ndarray:
        ...

    def score(self, X: np.ndarray, y: np.ndarray) -> float:
        ...
```

### 3. ä½¿ç”¨ TypedDict å®šä¹‰ç»“æ„åŒ–æ•°æ®

```python
from typing import TypedDict, List, Optional, Union

class ModelConfig(TypedDict):
    """æ¨¡å‹é…ç½®å­—å…¸"""
    model_type: str
    input_dim: int
    hidden_dims: List[int]
    activation: str
    dropout_rate: Optional[float]
    optimizer: str
    learning_rate: float
    batch_size: int
    epochs: int

class ExperimentResult(TypedDict):
    """å®éªŒç»“æœå­—å…¸"""
    model_name: str
    train_accuracy: float
    test_accuracy: float
    training_time: float
    final_loss: float
    best_epoch: int
    hyperparameters: ModelConfig

# ä½¿ç”¨ç¤ºä¾‹
config: ModelConfig = {
    "model_type": "MLP",
    "input_dim": 784,
    "hidden_dims": [256, 128, 64],
    "activation": "relu",
    "dropout_rate": 0.5,
    "optimizer": "adam",
    "learning_rate": 0.001,
    "batch_size": 32,
    "epochs": 100
}
```

## ğŸ”¬ ç§‘å­¦è®¡ç®—ç‰¹å®šç±»å‹

### 1. ç‰©ç†é‡ç±»å‹

```python
from typing import NewType, Union
import numpy as np

# åŸºç¡€ç‰©ç†é‡
Time = NewType('Time', float)           # æ—¶é—´ (s)
Length = NewType('Length', float)       # é•¿åº¦ (m)
Mass = NewType('Mass', float)           # è´¨é‡ (kg)
Energy = NewType('Energy', float)       # èƒ½é‡ (J)
Temperature = NewType('Temperature', float)  # æ¸©åº¦ (K)

# å¯¼å‡ºç‰©ç†é‡
Velocity = NewType('Velocity', float)   # é€Ÿåº¦ (m/s)
Acceleration = NewType('Acceleration', float)  # åŠ é€Ÿåº¦ (m/sÂ²)
Force = NewType('Force', float)         # åŠ› (N)
Power = NewType('Power', float)         # åŠŸç‡ (W)

# æ•°ç»„å½¢å¼
TimeSeries = NewType('TimeSeries', np.ndarray)
Spectrum = NewType('Spectrum', np.ndarray)
Wavefunction = NewType('Wavefunction', np.ndarray)
Hamiltonian = NewType('Hamiltonian', np.ndarray)

# ä½¿ç”¨ç¤ºä¾‹
def kinetic_energy(mass: Mass, velocity: Velocity) -> Energy:
    """è®¡ç®—åŠ¨èƒ½"""
    return Energy(0.5 * float(mass) * float(velocity) ** 2)

def fourier_transform(signal: TimeSeries) -> Spectrum:
    """å‚…é‡Œå¶å˜æ¢"""
    return Spectrum(np.fft.fft(signal))
```

### 2. ç»Ÿè®¡å­¦ç±»å‹

```python
from typing import NamedTuple, Union
import numpy as np

class Statistics(NamedTuple):
    """ç»Ÿè®¡ç»“æœ"""
    mean: float
    std: float
    min: float
    max: float
    median: float
    q25: float
    q75: float

class ConfidenceInterval(NamedTuple):
    """ç½®ä¿¡åŒºé—´"""
    lower: float
    upper: float
    confidence_level: float

# ä½¿ç”¨ç¤ºä¾‹
def calculate_statistics(data: np.ndarray) -> Statistics:
    """è®¡ç®—æè¿°æ€§ç»Ÿè®¡"""
    return Statistics(
        mean=np.mean(data),
        std=np.std(data),
        min=np.min(data),
        max=np.max(data),
        median=np.median(data),
        q25=np.percentile(data, 25),
        q75=np.percentile(data, 75)
    )

def bootstrap_mean(
    data: np.ndarray,
    n_bootstrap: int = 1000
) -> ConfidenceInterval:
    """è‡ªåŠ©æ³•è®¡ç®—å‡å€¼ç½®ä¿¡åŒºé—´"""
    # å®ç°è‡ªåŠ©æ³•é‡‡æ ·
    return ConfidenceInterval(
        lower=0.0,
        upper=1.0,
        confidence_level=0.95
    )
```

## ğŸ› ï¸ å®ç”¨å·¥å…·å’ŒæŠ€å·§

### 1. ä½¿ç”¨ dataclasses

```python
from dataclasses import dataclass
from typing import Optional, List
import numpy as np

@dataclass
class QuantumState:
    """é‡å­æ€è¡¨ç¤º"""
    amplitudes: np.ndarray
    basis_labels: List[str]
    energy: Optional[float] = None
    metadata: Optional[dict] = None

    def __post_init__(self):
        # éªŒè¯å½’ä¸€åŒ–
        norm = np.linalg.norm(self.amplitudes)
        if not np.isclose(norm, 1.0):
            self.amplitudes = self.amplitudes / norm

    def probability(self, index: int) -> float:
        """è®¡ç®—ç‰¹å®šåŸºçš„æ¦‚ç‡"""
        return float(np.abs(self.amplitudes[index]) ** 2)

@dataclass
class SimulationParameters:
    """ä»¿çœŸå‚æ•°"""
    time_step: float
    total_time: float
    num_steps: int

    @property
    def dt(self) -> float:
        return self.time_step

    @property
    def T(self) -> float:
        return self.total_time

    def __post_init__(self):
        # è‡ªåŠ¨è®¡ç®—æ­¥æ•°
        if self.num_steps == 0:
            self.num_steps = int(self.total_time // self.time_step)
```

### 2. ä½¿ç”¨ Protocol å®šä¹‰æ¥å£

```python
from typing import Protocol, runtime_checkable
import numpy as np

@runtime_checkable
class Optimizer(Protocol):
    """ä¼˜åŒ–å™¨æ¥å£"""

    learning_rate: float

    def step(self, gradient: np.ndarray) -> np.ndarray:
        """æ‰§è¡Œä¸€æ­¥ä¼˜åŒ–"""
        ...

    def reset(self) -> None:
        """é‡ç½®ä¼˜åŒ–å™¨çŠ¶æ€"""
        ...

@runtime_checkable
class LossFunction(Protocol):
    """æŸå¤±å‡½æ•°æ¥å£"""

    def __call__(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:
        """è®¡ç®—æŸå¤±å€¼"""
        ...

    def gradient(self, y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:
        """è®¡ç®—æ¢¯åº¦"""
        ...

# ä½¿ç”¨ç¤ºä¾‹
def train_model(
    model: Any,
    optimizer: Optimizer,
    loss_fn: LossFunction,
    X: np.ndarray,
    y: np.ndarray,
    epochs: int
) -> List[float]:
    """è®­ç»ƒæ¨¡å‹çš„é€šç”¨å‡½æ•°"""
    losses = []
    for epoch in range(epochs):
        # å‰å‘ä¼ æ’­
        y_pred = model(X)

        # è®¡ç®—æŸå¤±
        loss = loss_fn(y, y_pred)
        losses.append(loss)

        # åå‘ä¼ æ’­
        gradient = loss_fn.gradient(y, y_pred)
        params = optimizer.step(gradient)

    return losses
```

## ğŸ” ç±»å‹æ£€æŸ¥å·¥å…·

### 1. ä½¿ç”¨ mypy è¿›è¡Œé™æ€æ£€æŸ¥

#### å®‰è£…

```bash
# åŸºç¡€å®‰è£…
pip install mypy

# æˆ–ä½¿ç”¨ conda
conda install mypy -c conda-forge

# ç§‘å­¦è®¡ç®—æ”¯æŒï¼ˆæ¨èï¼‰
pip install numpy-stubs pandas-stubs types-scipy types-matplotlib

# éªŒè¯å®‰è£…
mypy --version
```

#### ä½¿ç”¨

```bash
# åŸºæœ¬ä½¿ç”¨
mypy your_script.py

# ä¸¥æ ¼æ¨¡å¼ï¼ˆæ¨èç”¨äºæ–°é¡¹ç›®ï¼‰
mypy your_script.py --strict

# æ£€æŸ¥æ•´ä¸ªåŒ…
mypy your_package/

# æ˜¾ç¤ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
mypy your_script.py --show-error-codes

# é…ç½®æ–‡ä»¶
mypy your_script.py --config-file mypy.ini
```

#### é…ç½®æ–‡ä»¶ (mypy.ini)

```ini
[mypy]
python_version = 3.9
strict = True
warn_return_any = True
warn_unused_configs = True
disallow_untyped_defs = True
disallow_incomplete_defs = True
check_untyped_defs = True
disallow_untyped_decorators = True
no_implicit_optional = True
warn_redundant_casts = True
warn_unused_ignores = True
warn_no_return = True
warn_unreachable = True
strict_equality = True

# ç‰¹å®šæ¨¡å—é…ç½®
[mypy-numpy.*]
ignore_missing_imports = True

[mypy-matplotlib.*]
ignore_missing_imports = True

[mypy-scipy.*]
ignore_missing_imports = True
```

#### å¸¸è§é—®é¢˜

```bash
# å¦‚æœé‡åˆ° "cannot import implementation" é”™è¯¯
pip install --upgrade mypy

# å¦‚æœ NumPy ç±»å‹æ£€æŸ¥æŠ¥é”™ï¼Œç¡®ä¿å®‰è£…äº† numpy-stubs
pip install numpy-stubs

# å¯¹äºæŸäº›ç¬¬ä¸‰æ–¹åº“ï¼Œå¯ä»¥å¿½ç•¥ç¼ºå¤±çš„å­˜æ ¹
# åœ¨ mypy.ini ä¸­æ·»åŠ ï¼š
[mypy-third_party_library.*]
ignore_missing_imports = True
```

### 2. ä½¿ç”¨ VS Code æ™ºèƒ½æç¤º

```json
// .vscode/settings.json
{
    "python.analysis.typeCheckingMode": "basic",
    "python.analysis.autoImportCompletions": true,
    "python.analysis.completeFunctionParens": true
}
```

## ğŸ“ æœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„ç²¾åº¦

```python
# æ˜ç¡®æŒ‡å®šæ•°å€¼ç²¾åº¦
def create_model_weights(input_dim: int, output_dim: int) -> np.ndarray:
    """åˆ›å»ºæ¨¡å‹æƒé‡ï¼Œæ˜ç¡®ä½¿ç”¨ float32"""
    return np.random.randn(input_dim, output_dim).astype(np.float32)

# ä½¿ç”¨ç±»å‹åˆ«å
Float32Array = np.ndarray
Float64Array = np.ndarray

def process_image(image: Float32Array) -> Float64Array:
    """å¤„ç†å›¾åƒï¼Œè½¬æ¢ç²¾åº¦"""
    return image.astype(np.float64)
```

### 2. é¿å…è¿‡åº¦å¤æ‚åŒ–

```python
# âœ… å¥½çš„å®è·µï¼šç®€æ´æ˜äº†
def compute_error(true_vals: np.ndarray, pred_vals: np.ndarray) -> float:
    """è®¡ç®—é¢„æµ‹è¯¯å·®"""
    return float(np.mean((true_vals - pred_vals) ** 2))

# âŒ é¿å…ï¼šè¿‡åº¦å¤æ‚
def compute_error(
    true_vals: Union[np.ndarray, List[float]],
    pred_vals: Union[np.ndarray, List[float]],
    metric_type: str = "mse"
) -> Union[float, np.ndarray]:
    ...
```

### 3. ä½¿ç”¨ Optional å¤„ç†ç¼ºå¤±å€¼

```python
from typing import Optional

def load_data(file_path: str, normalize: Optional[bool] = None) -> np.ndarray:
    """åŠ è½½æ•°æ®ï¼Œå¯é€‰æ‹©æ˜¯å¦å½’ä¸€åŒ–"""
    data = np.loadtxt(file_path)

    if normalize is None:
        # è‡ªåŠ¨åˆ¤æ–­
        normalize = data.std() > 1.0

    if normalize:
        data = (data - data.mean()) / data.std()

    return data
```

## ğŸ¯ ç§‘å­¦è®¡ç®—ç¤ºä¾‹

### 1. æ•°å€¼ç§¯åˆ†å‡½æ•°

```python
from typing import Callable, Union
import numpy as np

# å‡½æ•°ç±»å‹å®šä¹‰
Integrand = Callable[[float], float]

def trapezoidal_rule(
    f: Integrand,
    a: float,
    b: float,
    n: int = 1000
) -> float:
    """æ¢¯å½¢æ³•åˆ™æ•°å€¼ç§¯åˆ†"""
    x = np.linspace(a, b, n + 1)
    y = f(x)
    h = (b - a) / n
    return float(h * (0.5 * y[0] + y[1:-1].sum() + 0.5 * y[-1]))

def adaptive_simpson(
    f: Integrand,
    a: float,
    b: float,
    tol: float = 1e-6
) -> float:
    """è‡ªé€‚åº”è¾›æ™®æ£®ç§¯åˆ†"""
    # å®ç°è‡ªé€‚åº”è¾›æ™®æ£®ç®—æ³•
    ...
```

### 2. æœºå™¨å­¦ä¹ æ¨¡å‹

```python
from typing import Tuple, Optional
import numpy as np

class LinearRegression:
    """çº¿æ€§å›å½’æ¨¡å‹"""

    def __init__(self, fit_intercept: bool = True):
        self.fit_intercept: bool = fit_intercept
        self.weights: Optional[np.ndarray] = None
        self.bias: Optional[float] = None

    def fit(
        self,
        X: np.ndarray,
        y: np.ndarray
    ) -> 'LinearRegression':
        """è®­ç»ƒæ¨¡å‹"""
        if self.fit_intercept:
            X_b = np.c_[np.ones(X.shape[0]), X]
            weights_b = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y
            self.bias = float(weights_b[0])
            self.weights = weights_b[1:]
        else:
            self.weights = np.linalg.inv(X.T @ X) @ X.T @ y
            self.bias = 0.0
        return self

    def predict(self, X: np.ndarray) -> np.ndarray:
        """é¢„æµ‹"""
        if self.weights is None:
            raise ValueError("Model not fitted")
        return X @ self.weights + self.bias

    def score(
        self,
        X: np.ndarray,
        y: np.ndarray
    ) -> float:
        """è®¡ç®— RÂ² åˆ†æ•°"""
        y_pred = self.predict(X)
        ss_res = ((y - y_pred) ** 2).sum()
        ss_tot = ((y - y.mean()) ** 2).sum()
        return float(1 - ss_res / ss_tot)
```

## ğŸ“š å‚è€ƒèµ„æº

- [PEP 484 - Type Hints](https://www.python.org/dev/peps/pep-0484/)
- [PEP 585 - Built-in Generic Types](https://www.python.org/dev/peps/pep-0585/)
- [mypy Documentation](https://mypy.readthedocs.io/)
- [Type Cheatsheet](https://mypy.readthedocs.io/en/stable/cheat_sheet_py3.html)

---

è®°ä½ï¼šå¥½çš„ç±»å‹æ³¨è§£åº”è¯¥åƒå¥½çš„æ–‡æ¡£ä¸€æ ·æ¸…æ™°ï¼Œæ—¢è¦å‡†ç¡®åˆè¦ç®€æ´ã€‚åœ¨ç§‘å­¦è®¡ç®—ä¸­ï¼Œç‰¹åˆ«è¦æ³¨æ„æ•°å€¼ç²¾åº¦å’Œæ•°æ®ç»´åº¦çš„æ­£ç¡®è¡¨è¾¾ã€‚